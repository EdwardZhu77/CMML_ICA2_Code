{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3EOqgl1ZqfmE"},"outputs":[],"source":["!pip install --quiet scvi-colab\n","from scvi_colab import install\n","\n","install()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSRGJ42EguIG"},"outputs":[],"source":["import tempfile\n","import anndata as ad\n","import matplotlib.pyplot as plt\n","import mudata as md\n","import muon\n","import numpy as np\n","import scanpy as sc\n","import scvi\n","import seaborn as sns\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P2HfBbJhqfmF"},"outputs":[],"source":["scvi.settings.seed = 0\n","print(\"Last run with scvi-tools version:\", scvi.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bnMRRihguIJ"},"outputs":[],"source":["sc.set_figure_params(figsize=(6, 6), frameon=False)\n","sns.set_theme()\n","torch.set_float32_matmul_precision(\"high\")\n","\n","# --- Google Drive and Path Definitions (keep your existing, correct path logic) ---\n","import os\n","from google.colab import drive # Ensure this is imported\n","\n","try:\n","    drive.mount('/content/drive', force_remount=True)\n","    print(\"Google Drive mounted successfully.\")\n","except Exception as e:\n","    print(f\"Error mounting Google Drive: {e}\")\n","    raise # Stop if drive cannot be mounted\n","\n","# Define the path to YOUR processed H5AD file\n","# This should point to the output of your preprocessing script (Block 8 from our previous discussion)\n","# For example, if you saved it as \"pbmc10k_cite_seq_processed_for_totalVI.h5ad\"\n","# in your 'processed_data_dir'\n","gdrive_base_path = '/content/drive/My Drive/CMML_ICA2/' # Your main project folder\n","# Directory where your processed H5AD file is located\n","processed_data_dir = os.path.join(gdrive_base_path, 'data_pbmc10k_mtx/processed/') # Path from your previous successful save\n","your_processed_h5ad_filename = \"pbmc10k_cite_seq_processed_for_totalVI.h5ad\" # The name of your H5AD file\n","path_to_your_h5ad = os.path.join(processed_data_dir, your_processed_h5ad_filename)\n","\n","print(f\"Attempting to load processed AnnData from: {path_to_your_h5ad}\")"]},{"cell_type":"code","source":["# --- Load YOUR processed H5AD file ---\n","try:\n","    # adata = scvi.data.pbmcs_10x_cite_seq(save_path=gdrive_save_path) # OLD LINE - REMOVE OR COMMENT OUT\n","\n","    # NEW LINE: Load your preprocessed H5AD file\n","    if os.path.exists(path_to_your_h5ad):\n","        adata_main_filtered = sc.read_h5ad(path_to_your_h5ad) # Use scanpy.read_h5ad\n","        print(\"Successfully loaded your processed H5AD file.\")\n","        print(\"Loaded AnnData object (adata_main_filtered):\")\n","        print(adata_main_filtered)\n","        # You should see the obs, var, obsm, layers, uns that you saved in your preprocessing script\n","        if \"protein_counts\" in adata_main_filtered.obsm:\n","            print(f\"  protein_counts shape: {adata_main_filtered.obsm['protein_counts'].shape}\")\n","        if \"ground_truth_cell_type\" in adata_main_filtered.obs:\n","            print(\"  'ground_truth_cell_type' found in .obs.\")\n","            print(adata_main_filtered.obs[\"ground_truth_cell_type\"].value_counts().head())\n","        if \"counts\" in adata_main_filtered.layers:\n","            print(\"  'counts' layer found.\")\n","    else:\n","        print(f\"ERROR: Your processed H5AD file was not found at {path_to_your_h5ad}\")\n","        print(\"Please ensure the path and filename are correct and the preprocessing script (Block 8) ran successfully.\")\n","        adata_main_filtered = None # Set to None if loading failed\n","except Exception as e:\n","    print(f\"Error loading your processed H5AD file: {e}\")\n","    adata_main_filtered = None\n","    import traceback\n","    traceback.print_exc()\n","\n","\n","# --- Inline backend config (keep this) ---\n","# %config InlineBackend.print_figure_kwargs={\"facecolor\": \"w\"}\n","# %config InlineBackend.figure_format=\"retina\"\n","\n","# --- Check if data loaded successfully before proceeding ---\n","if adata_main_filtered is None or adata_main_filtered.n_obs == 0:\n","    print(\"\\nCRITICAL ERROR: Data loading failed or resulted in an empty AnnData object. Cannot proceed.\")\n","else:\n","    print(\"\\nData loading section complete. adata_main_filtered is ready.\")"],"metadata":{"id":"ChdGD132dg2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dqFHL3TugIPi"},"outputs":[],"source":["adata = adata_main_filtered.copy()\n","adata"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"viweSAyuqfmG"},"outputs":[],"source":["adata.layers[\"counts\"] = adata.X.copy()\n","sc.pp.normalize_total(adata)\n","sc.pp.log1p(adata)\n","adata.obs_names_make_unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWxvw8fiqfmG"},"outputs":[],"source":["protein_adata = ad.AnnData(adata.obsm[\"protein_counts\"])\n","protein_adata.obs_names = adata.obs_names\n","del adata.obsm[\"protein_counts\"]\n","mdata = md.MuData({\"rna\": adata, \"protein\": protein_adata})\n","mdata"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0x-haM2IxV6d"},"outputs":[],"source":["sc.pp.highly_variable_genes(\n","    mdata.mod[\"rna\"],\n","    n_top_genes=4000,\n","    flavor=\"seurat_v3\",\n","    # batch_key=\"batch\",\n","    layer=\"counts\",\n",")\n","# Place subsetted counts in a new modality\n","mdata.mod[\"rna_subset\"] = mdata.mod[\"rna\"][:, mdata.mod[\"rna\"].var[\"highly_variable\"]].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HCl6JRGGqfmH"},"outputs":[],"source":["mdata.update()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbiiaVLuqfmH"},"outputs":[],"source":["mdata"]},{"cell_type":"code","source":["adata"],"metadata":{"id":"H6Sp2d7o0Wrn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3lroWyRxfii"},"outputs":[],"source":["scvi.model.TOTALVI.setup_mudata(\n","    mdata,\n","    rna_layer=\"counts\",\n","    protein_layer=None,\n","    #batch_key=\"batch\",\n","    modalities={\n","        \"rna_layer\": \"rna_subset\",\n","        \"protein_layer\": \"protein\",\n","        \"batch_key\": \"rna_subset\",\n","    },\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZlH_GXhguIU"},"outputs":[],"source":["model = scvi.model.TOTALVI(mdata)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KI-dQvmERrSF"},"outputs":[],"source":["model.train()"]},{"cell_type":"code","source":["model_save_path = os.path.join(gdrive_base_path, \"totalVI_pbmc_model\")\n","model.save(model_save_path, overwrite=True)\n","print(f\"totalVI model saved to: {model_save_path}\")\n","\n","# loaded_model = scvi.model.TOTALVI.load(model_save_path, adata=mdata)"],"metadata":{"id":"8u89fkSm-jaS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure history values are simple lists of floats or pandas Series\n","# model.history[\"elbo_train\"] and model.history[\"elbo_validation\"]\n","# are typically pandas Series after training if accessed directly.\n","# If they are lists of tensors, you would need to convert them.\n","# Let's assume they are pandas Series or convertible to them for min/max.\n","\n","# For robustness, convert to numpy arrays of floats if they are not already\n","try:\n","    # If model.history values are DataFrames or Series from scvi's history tracking\n","    elbo_train_values = model.history[\"elbo_train\"].values.astype(float)\n","    elbo_val_values = model.history[\"elbo_validation\"].values.astype(float)\n","except AttributeError:\n","    # If they are lists of tensors or simple floats\n","    elbo_train_values = np.array([v.item() if hasattr(v, 'item') else float(v) for v in model.history[\"elbo_train\"]]).astype(float)\n","    elbo_val_values = np.array([v.item() if hasattr(v, 'item') else float(v) for v in model.history[\"elbo_validation\"]]).astype(float)\n","\n","\n","if len(elbo_train_values) == 0 or len(elbo_val_values) == 0:\n","    print(\"ERROR: Training history is empty. Cannot plot ELBO curves.\")\n","    # Handle this error, maybe skip plotting\n","else:\n","    last_val_train = elbo_train_values[-1]\n","    last_val_valid = elbo_val_values[-1]\n","\n","    global_min_loss_train = np.min(elbo_train_values)\n","    global_min_loss_val = np.min(elbo_val_values)\n","    global_min_loss = min(global_min_loss_train, global_min_loss_val)\n","\n","    # last_max_loss should be the maximum of the *last* training and validation losses\n","    last_max_loss = max(last_val_train, last_val_valid) # REMOVED [0]\n","\n","    global_max_loss_train = np.max(elbo_train_values)\n","    global_max_loss_val = np.max(elbo_val_values)\n","    global_max_loss = max(global_max_loss_train, global_max_loss_val)\n","\n","    # Compute the min and max for y-axis limits\n","    # min_loss for ylim should be based on the overall minimum observed\n","    min_loss_for_ylim = global_min_loss\n","    # max_loss for ylim should be based on overall maximum, but the original logic tried to zoom in\n","    # Let's simplify the ylim calculation slightly for clarity, or use the original logic if it was intended for specific zooming.\n","\n","    # Original zooming logic:\n","    # ylim_min = 0.995 * min_loss_for_ylim\n","    # ylim_max = min(global_max_loss, ylim_min + (last_max_loss - ylim_min) * 4)\n","\n","    # Simpler approach (full range, or slightly zoomed):\n","    plot_min_val = np.min(elbo_val_values[10:]) # Ignore first few noisy epochs for validation min for zooming\n","    plot_min_train = np.min(elbo_train_values[10:])\n","    ylim_min_plot = 0.995 * min(plot_min_val, plot_min_train) # Zoom in on the converged part\n","\n","    # Use a reasonable upper bound, e.g., the max of the later part of validation or slightly above last values\n","    # Or cap by the initial high values if they are very large.\n","    # The original ylim_max logic was a bit complex to ensure the initial steep drop doesn't make the converged part too flat.\n","    # Let's try to replicate the original intent more cleanly if possible or use a simpler zoom.\n","\n","    # Re-evaluating original ylim logic:\n","    # It seems designed to show the converged part well, while still hinting at earlier values.\n","    # Ensure all components are float\n","    ylim_min = 0.995 * float(min_loss_for_ylim)\n","    # Ensure last_max_loss and global_max_loss are floats for the calculation below\n","    last_max_loss_float = float(last_max_loss)\n","    global_max_loss_float = float(global_max_loss)\n","\n","    # Cap the upper limit to avoid extreme early values dominating the scale\n","    # Consider the maximum of the later half of the validation loss as a sensible upper bound for the \"zoomed\" view\n","    if len(elbo_val_values) > 20: # Ensure there are enough points\n","        sensible_upper_bound = np.max(elbo_val_values[len(elbo_val_values)//2:]) * 1.05 # 5% above max of later half\n","    else:\n","        sensible_upper_bound = global_max_loss_float * 1.05\n","\n","    ylim_max_candidate = ylim_min + (last_max_loss_float - ylim_min) * 4\n","    ylim_max = min(sensible_upper_bound, ylim_max_candidate, global_max_loss_float) # Ensure it doesn't exceed global max\n","\n","    # Ensure ylim_min is less than ylim_max\n","    if ylim_min >= ylim_max:\n","        print(\"Warning: ylim_min >= ylim_max. Plotting full y-axis range instead.\")\n","        ylim_min = None # Let matplotlib auto-scale\n","        ylim_max = None\n","\n","\n","    # --- Plotting (should work now if ylim_min/max are proper floats) ---\n","    fig, ax = plt.subplots(1, 1)\n","    # Plot using the processed numpy arrays directly if pandas Series plotting causes issues\n","    epochs_train = np.arange(len(elbo_train_values))\n","    epochs_val = np.arange(len(elbo_val_values))\n","\n","    ax.plot(epochs_train, elbo_train_values, label=\"train\")\n","    ax.plot(epochs_val, elbo_val_values, label=\"validation\")\n","\n","    ax.set_title(\"Negative ELBO over training epochs\")\n","    ax.set_xlabel(\"epoch\") # Add x-axis label\n","    ax.set_ylabel(\"Negative ELBO\") # Add y-axis label\n","    if ylim_min is not None and ylim_max is not None:\n","        ax.set_ylim(ylim_min, ylim_max)\n","    ax.legend()\n","    plt.show() # Display the plot\n","\n","    # Save the figure\n","    elbo_plot_path = os.path.join(gdrive_base_path, \"totalVI_elbo_curves.png\") # Use your gdrive_save_path\n","    fig.savefig(elbo_plot_path, dpi=300, bbox_inches='tight')\n","    print(f\"ELBO plot saved to {elbo_plot_path}\")"],"metadata":{"id":"-ToDM_jWlAyB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adata_totalVI_latent = model.get_latent_representation()\n","mdata.obsm[\"X_totalVI\"] = adata_totalVI_latent\n","mdata.write_h5mu(os.path.join(gdrive_base_path, \"pbmc_mdata_with_totalVI_latent.h5mu\"))\n","print(\"MuData object with totalVI latent space saved.\")"],"metadata":{"id":"WBB0GUzC-0s9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77EOeE1zqfmQ"},"outputs":[],"source":["rna = mdata.mod[\"rna_subset\"]\n","protein = mdata.mod[\"protein\"]\n","#rna = mdata1.mod[\"rna_subset\"]\n","#protein = mdata1.mod[\"protein\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhCIADQXguIc"},"outputs":[],"source":["# arbitrarily store latent in rna modality\n","TOTALVI_LATENT_KEY = \"X_totalVI\"\n","rna.obsm[TOTALVI_LATENT_KEY] = model.get_latent_representation()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60la_MI0qfmQ"},"outputs":[],"source":["rna_denoised, protein_denoised = model.get_normalized_expression(n_samples=25, return_mean=True)\n","rna.layers[\"denoised_rna\"] = rna_denoised\n","protein.layers[\"denoised_protein\"] = protein_denoised\n","\n","protein.layers[\"protein_foreground_prob\"] = 100 * model.get_protein_foreground_probability(\n","    n_samples=25, return_mean=True\n",")\n","parsed_protein_names = [p.split(\"_\")[0] for p in protein.var_names]\n","protein.var[\"clean_names\"] = parsed_protein_names\n","mdata.update()\n","#mdata1.update()"]},{"cell_type":"code","source":["mdata_processed_path = os.path.join(gdrive_base_path, \"mdata_processed_totalVI.h5mu\")\n","mdata.write_h5mu(mdata_processed_path)\n","print(f\"Processed MuData object saved to: {mdata_processed_path}\")"],"metadata":{"id":"Ol43sE9bEQhF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TOTALVI_CLUSTERS_KEY = \"leiden_totalVI\"\n","\n","sc.pp.neighbors(rna, use_rep=TOTALVI_LATENT_KEY, key_added=\"totalVI_neighbors_rna\")\n","sc.tl.umap(rna, neighbors_key=\"totalVI_neighbors_rna\", min_dist=0.3)\n","sc.tl.leiden(rna, key_added=TOTALVI_CLUSTERS_KEY, neighbors_key=\"totalVI_neighbors_rna\", resolution=0.5)\n","mdata.update()\n"],"metadata":{"id":"egFXWoWaEdqr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xf4XuR83guIg"},"outputs":[],"source":["umap_basis_key_muon = \"rna_subset:X_umap\"\n","ground_truth_color_key_muon = \"rna_subset:ground_truth_cell_type\"\n","\n","if \"rna_subset\" not in mdata.mod:\n","    print(\"ERROR: Modality 'rna_subset' not found in mdata.\")\n","elif \"X_umap\" not in mdata.mod[\"rna_subset\"].obsm:\n","    print(\"ERROR: Basis 'X_umap' not found in mdata.mod['rna_subset'].obsm.\")\n","    print(\"  Available obsm keys in rna_subset:\", list(mdata.mod[\"rna_subset\"].obsm.keys()))\n","elif \"ground_truth_cell_type\" not in mdata.mod[\"rna_subset\"].obs:\n","    print(\"ERROR: Color key 'ground_truth_cell_type' not found in mdata.mod['rna_subset'].obs.\")\n","    print(\"  Available obs keys in rna_subset:\", mdata.mod[\"rna_subset\"].obs.columns.tolist())\n","else:\n","    umap_gt_path = os.path.join(gdrive_base_path, \"totalVI_umap_by_ground_truth_muon.png\") # Use your figure_dir\n","    plt.figure(figsize=(8, 7)) # Adjust figsize for legend if needed\n","    muon.pl.embedding(\n","        mdata,\n","        basis=umap_basis_key_muon,\n","        color=ground_truth_color_key_muon,\n","        title=\"totalVI UMAP by Ground Truth Cell Type (Muon)\",\n","        show=False,\n","        frameon=False,\n","        legend_loc=\"on data\" if mdata.mod[\"rna_subset\"].obs[\"ground_truth_cell_type\"].nunique() < 28 else \"right margin\",\n","        legend_fontsize=8 # Adjust legend fontsize\n","    )\n","    plt.savefig(umap_gt_path, dpi=300, bbox_inches='tight')\n","    plt.close()\n","    print(f\"UMAP by Ground Truth (using Muon) saved to {umap_gt_path}\")"]},{"cell_type":"code","source":["mdata"],"metadata":{"id":"4d5HRbJvqSL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Block for Visualizing and Saving Leiden Clustering Results (Revised)\n","\n","import matplotlib.pyplot as plt # Ensure plt is imported\n","import pandas as pd # Ensure pandas is imported\n","import muon # Ensure muon is imported for plotting\n","\n","leiden_resolution = 0.5 # This was the resolution used\n","umap_leiden_path = os.path.join(gdrive_base_path, \"totalVI_umap_by_leiden_muon.png\") # Use your figure_dir\n","plt.figure(figsize=(8, 7)) # Adjusted figsize\n","\n","# Define keys for muon plotting\n","umap_basis_for_leiden_plot = \"rna_subset:X_umap\" # UMAP coordinates from rna_subset modality\n","leiden_color_for_plot = \"rna_subset:leiden_totalVI\" # Leiden labels from rna_subset modality\n","\n","# Check if these keys/paths are valid in your mdata object\n","plot_leiden_map = True\n","if \"rna_subset\" not in mdata.mod:\n","    print(\"ERROR: Modality 'rna_subset' not found.\")\n","    plot_leiden_map = False\n","if plot_leiden_map and \"X_umap\" not in mdata.mod[\"rna_subset\"].obsm:\n","    print(f\"ERROR: Basis 'X_umap' not found in mdata.mod['rna_subset'].obsm. Available: {list(mdata.mod['rna_subset'].obsm.keys())}\")\n","    plot_leiden_map = False\n","if plot_leiden_map and \"leiden_totalVI\" not in mdata.mod[\"rna_subset\"].obs:\n","    print(f\"ERROR: Color key 'leiden_totalVI' not found in mdata.mod['rna_subset'].obs. Available: {mdata.mod['rna_subset'].obs.columns.tolist()}\")\n","    plot_leiden_map = False\n","\n","if plot_leiden_map:\n","    muon.pl.embedding(\n","        mdata,\n","        basis=umap_basis_for_leiden_plot,\n","        color=leiden_color_for_plot,\n","        title=f\"totalVI UMAP by Leiden (res={leiden_resolution}, Muon)\",\n","        show=False,\n","        frameon=False,\n","        legend_loc=\"on data\", # legend directly on clusters\n","        legend_fontsize=8 # Adjust as needed\n","    )\n","    plt.savefig(umap_leiden_path, dpi=300, bbox_inches='tight')\n","    plt.close()\n","    print(f\"UMAP by Leiden clusters (using Muon) saved to {umap_leiden_path}\")\n","else:\n","    print(\"Skipping UMAP by Leiden plot due to missing data.\")\n","\n","\n","if \"leiden_totalVI\" in mdata.obs:\n","    totalvi_leiden_labels_df = pd.DataFrame({\n","        \"cell_barcode\": mdata.obs_names, # Global obs_names\n","        \"leiden_totalVI\": mdata.obs[\"leiden_totalVI\"] # Global leiden_totalVI\n","    })\n","    leiden_labels_save_path = os.path.join(processed_data_dir, \"totalVI_leiden_labels.csv\")\n","    totalvi_leiden_labels_df.to_csv(leiden_labels_save_path, index=False)\n","    print(f\"totalVI Leiden cluster labels saved to {leiden_labels_save_path}\")\n","else:\n","    print(\"ERROR: 'leiden_totalVI' not found in mdata.obs. Cannot save labels.\")\n","\n","mdata_final_save_path = os.path.join(gdrive_base_path, \"pbmc_mdata_with_totalVI_latent_umap_leiden.h5mu\") # Use your gdrive_base_path\n","try:\n","    mdata.write_h5mu(mdata_final_save_path) # Removed overwrite=True, as you might not want to overwrite if it's the first save here\n","    print(f\"MuData object with UMAP and Leiden results saved to {mdata_final_save_path}\")\n","except Exception as e:\n","    print(f\"Error saving final MuData object: {e}\")"],"metadata":{"id":"8tLL8faYpPxn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mdata"],"metadata":{"id":"sAYABm3rvX9V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Block for Saving PREVIOUSLY COMPUTED Denoised Expressions from MuData\n","\n","import pandas as pd # Ensure pandas is imported\n","import os # Ensure os is imported\n","\n","# --- Ensure your mdata object is loaded and up-to-date ---\n","# If you are in a new session or notebook, load the mdata object first:\n","# mdata_final_path = os.path.join(gdrive_base_path, \"pbmc_mdata_with_totalVI_latent_umap_leiden.h5mu\")\n","# if os.path.exists(mdata_final_path):\n","#     print(f\"Loading MuData object from: {mdata_final_path}\")\n","#     mdata = md.read_h5mu(mdata_final_path)\n","# else:\n","#     print(f\"ERROR: MuData file not found at {mdata_final_path}. Cannot proceed to save denoised data.\")\n","#     # Stop execution or handle error\n","\n","print(\"\\n--- Extracting and Saving Denoised Expressions from existing MuData layers ---\")\n","\n","# Paths for saving CSV files (ensure processed_data_dir is defined from Block 1)\n","denoised_rna_hvg_save_path = os.path.join(processed_data_dir, \"totalVI_denoised_rna_hvg_from_layer.csv\")\n","denoised_protein_save_path = os.path.join(processed_data_dir, \"totalVI_denoised_protein_from_layer.csv\")\n","\n","# 1. Extract and save Denoised RNA (from rna_subset modality's layer)\n","if \"rna_subset\" in mdata.mod and \"denoised_rna\" in mdata.mod[\"rna_subset\"].layers:\n","    # .layers[\"denoised_rna\"] should be a DataFrame or AnnData view that can be converted\n","    denoised_rna_df = pd.DataFrame(\n","        data=mdata.mod[\"rna_subset\"].layers[\"denoised_rna\"], # This should be cells x genes\n","        index=mdata.mod[\"rna_subset\"].obs_names,\n","        columns=mdata.mod[\"rna_subset\"].var_names\n","    )\n","    denoised_rna_df.to_csv(denoised_rna_hvg_save_path)\n","    print(f\"Denoised HVG RNA expression (from layer) saved to: {denoised_rna_hvg_save_path}\")\n","    print(f\"  Shape of saved denoised RNA: {denoised_rna_df.shape}\")\n","else:\n","    print(\"ERROR: 'denoised_rna' layer not found in 'rna_subset' modality of mdata.\")\n","\n","# 2. Extract and save Denoised Protein (from protein modality's layer)\n","if \"protein\" in mdata.mod and \"denoised_protein\" in mdata.mod[\"protein\"].layers:\n","    denoised_protein_df = pd.DataFrame(\n","        data=mdata.mod[\"protein\"].layers[\"denoised_protein\"], # This should be cells x proteins\n","        index=mdata.mod[\"protein\"].obs_names,\n","        columns=mdata.mod[\"protein\"].var_names # Or mdata.mod[\"protein\"].var[\"clean_names\"] if you prefer\n","    )\n","    denoised_protein_df.to_csv(denoised_protein_save_path)\n","    print(f\"Denoised Protein expression (from layer) saved to: {denoised_protein_save_path}\")\n","    print(f\"  Shape of saved denoised protein: {denoised_protein_df.shape}\")\n","else:\n","    print(\"ERROR: 'denoised_protein' layer not found in 'protein' modality of mdata.\")\n","\n","print(\"\\nExtraction and saving of denoised data from existing layers complete.\")"],"metadata":{"id":"IxQfTltbpPzw"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"https://github.com/scverse/scvi-tutorials/blob/1.3.0/multimodal/totalVI.ipynb","timestamp":1747225698833}],"gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.8"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"vscode":{"interpreter":{"hash":"b5142939ddaa1787bd1bfcf4c0ad4d35be0fa2237c553f986d37efcb39f03f79"}}},"nbformat":4,"nbformat_minor":0}